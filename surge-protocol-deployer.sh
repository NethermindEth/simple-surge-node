#!/bin/bash

set -e

# Select which Surge environment to use
echo
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘ âš ï¸  Select which Surge environment to use:                    â•‘"
echo "â•‘  1 for Devnet                                                â•‘"
echo "â•‘  2 for Staging                                               â•‘"
echo "â•‘  3 for Testnet                                               â•‘"
echo "â•‘ [default: Devnet]                                            â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo
read -r surge_environment

SURGE_ENVIRONMENT=${surge_environment:-1}

if [ "$SURGE_ENVIRONMENT" = "1" ]; then
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ ğŸš€  Using Devnet Environment                                 â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo

  # Select remote or local
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ Select remote or local:                                      â•‘"
  echo "â•‘  0 for local                                                 â•‘"
  echo "â•‘  1 for remote                                                â•‘"
  echo "â•‘ [default: local]                                             â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo
  read -r remote_or_local 

REMOTE_OR_LOCAL=${remote_or_local:-0}
  if [ "$REMOTE_OR_LOCAL" = "1" ]; then
    # Select which devnet machine to use
    echo
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘ Select which devnet machine to use:                          â•‘"
    echo "â•‘  1 for Devnet 1 (prover)                                     â•‘"
    echo "â•‘  2 for Devnet 2 (taiko-client)                               â•‘"
    echo "â•‘ [default: others]                                            â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo
    read -r devnet_machine

    DEVNET_MACHINE=${devnet_machine:-3}

    if [ "$devnet_machine" = "1" ]; then
      echo
      echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
      echo "â•‘ ğŸš€  Using Devnet 1 (prover)                                  â•‘"
      echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      echo
      export L1_RPC="https://devnet-one.surge.wtf/l1-rpc"
      export L1_BEACON_RPC="https://devnet-one.surge.wtf/l1-beacon"
      export L1_EXPLORER="https://devnet-one.surge.wtf/l1-block-explorer"
      export L2_RPC="https://devnet-one.surge.wtf/l2-rpc"
      export L2_EXPLORER="https://devnet-one.surge.wtf/l2-block-explorer"
      export L1_RELAYER="https://devnet-one.surge.wtf/l1-relayer"
      export L2_RELAYER="https://devnet-one.surge.wtf/l2-relayer"
    elif [ "$devnet_machine" = "2" ]; then
      echo
      echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
      echo "â•‘ ğŸš€  Using Devnet 2 (taiko-client)                            â•‘"
      echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      echo
      export L1_RPC="https://devnet-two.surge.wtf/l1-rpc"
      export L1_BEACON_RPC="https://devnet-two.surge.wtf/l1-beacon"
      export L1_EXPLORER="https://devnet-two.surge.wtf/l1-block-explorer"
      export L2_RPC="https://devnet-two.surge.wtf/l2-rpc"
      export L2_EXPLORER="https://devnet-two.surge.wtf/l2-block-explorer"
      export L1_RELAYER="https://devnet-two.surge.wtf/l1-relayer"
      export L2_RELAYER="https://devnet-two.surge.wtf/l2-relayer"
    else
      echo
      echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
      echo "â•‘ ğŸš€  Using others                                            â•‘"
      echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      echo
      export L1_RPC="http://$MACHINE_IP:32003"
      export L1_BEACON_RPC="http://$MACHINE_IP:33001"
      export L1_EXPLORER="http://$MACHINE_IP:36005"
      export L2_RPC="http://$MACHINE_IP:${L2_HTTP_PORT:-8547}"
      export L2_EXPLORER="http://$MACHINE_IP:${BLOCKSCOUT_FRONTEND_PORT:-3000}"
      export L1_RELAYER="http://$MACHINE_IP:4102"
      export L2_RELAYER="http://$MACHINE_IP:4103"
    fi
  else
    echo
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘ ğŸš€  Using local environment                                  â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo
    export L1_RPC="http://localhost:32003"
    export L1_BEACON_RPC="http://localhost:33001"
    export L1_EXPLORER="http://localhost:36005"
    export L2_RPC="http://localhost:${L2_HTTP_PORT:-8547}"
    export L2_EXPLORER="http://localhost:${BLOCKSCOUT_FRONTEND_PORT:-3000}"
    export L1_RELAYER="http://localhost:4102"
    export L2_RELAYER="http://localhost:4103"
  fi
elif [ "$SURGE_ENVIRONMENT" = "2" ]; then
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘                        âš ï¸  WARNING  âš ï¸                         â•‘"
  echo "â•‘                                                              â•‘"
  echo "â•‘  Using Staging Environment, skipping protocol deployment...  â•‘"
  echo "â•‘  Please execute surge-stack-deployer.sh directly             â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo
  echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
  echo "â”‚ ğŸ”§ REQUIRED ACTION: Copy the correct env file for staging    â”‚"
  echo "â”‚                                                              â”‚"
  echo "â”‚    Run: cp .env.staging .env                                 â”‚"
  echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
  echo
  exit 0
elif [ "$SURGE_ENVIRONMENT" = "3" ]; then
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘                        âš ï¸  WARNING  âš ï¸                         â•‘"
  echo "â•‘                                                              â•‘"
  echo "â•‘  Using Testnet Environment, skipping protocol deployment...  â•‘"
  echo "â•‘  Please execute surge-stack-deployer.sh directly             â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo
  echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
  echo "â”‚ ğŸ”§ REQUIRED ACTION: Copy the correct env file for Testnet    â”‚"
  echo "â”‚                                                              â”‚"
  echo "â”‚    Run: cp .env.testnet .env                                 â”‚"
  echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
  echo
  exit 0
fi

# Load environment variables from .env file if it exists
if [ -f .env ]; then
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ âœ… Loading environment variables from .env file...           â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo
  echo ""
  set -a  # automatically export all variables
  source .env
  set +a  # disable automatic export
else
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ âŒ Error: .env file not found                                â•‘"
  echo "â•‘                                                              â•‘"
  echo "â•‘ Automatically copying .env.devnet to .env                    â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo
  cp .env.devnet .env
  set -a  # automatically export all variables
  source .env
  set +a  # disable automatic export
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ âœ… Successfully loaded Devnet environment variables          â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo
fi

# Helper function to update environment variables in .env file
update_env_var() {
  local env_file="$1"
  local var_name="$2"
  local var_value="$3"
  
  # Check if the variable exists in the file
  if grep -q "^${var_name}=" "$env_file"; then
    # Update existing variable
    sed -i.bak "s|^${var_name}=.*|${var_name}=${var_value}|" "$env_file"
  else
    # Add new variable if it doesn't exist
    echo "${var_name}=${var_value}" >> "$env_file"
  fi
}

generate_prover_chain_spec() {
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ Generating prover chain spec list json...                    â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo

  GENESIS_TIME=$(curl -s http://localhost:33001/eth/v1/beacon/genesis | jq -r '.data.genesis_time')

  # Generate chain spec list
  cat > configs/chain_spec_list_default.json << EOF
[
  {
    "name": "surge_dev_l1",
    "chain_id": $L1_CHAINID,
    "max_spec_id": "CANCUN",
    "hard_forks": {
      "FRONTIER": {
        "Block": 0
      },
      "SHANGHAI": {
        "Timestamp": 0
      },
      "CANCUN": {
        "Timestamp": 0
      }
    },
    "eip_1559_constants": {
      "base_fee_change_denominator": "0x8",
      "base_fee_max_increase_denominator": "0x8",
      "base_fee_max_decrease_denominator": "0x8",
      "elasticity_multiplier": "0x2"
    },
    "l1_contract": null,
    "l2_contract": null,
    "rpc": "$L1_RPC",
    "beacon_rpc": "$L1_BEACON_RPC",
    "verifier_address_forks": {
      "FRONTIER": {
        "SGX": null,
        "SP1": null,
        "RISC0": null
      }
    },
    "genesis_time": $GENESIS_TIME,
    "seconds_per_slot": 12,
    "is_taiko": false
  },
  {
    "name": "surge_dev",
    "chain_id": $L2_CHAINID,
    "max_spec_id": "PACAYA",
    "hard_forks": {
      "HEKLA": {
        "Block": 0
      },
      "ONTAKE": {
        "Block": 1
      },
      "PACAYA": {
        "Block": 1
      },
      "CANCUN": "TBD"
    },
    "eip_1559_constants": {
      "base_fee_change_denominator": "0x8",
      "base_fee_max_increase_denominator": "0x8",
      "base_fee_max_decrease_denominator": "0x8",
      "elasticity_multiplier": "0x2"
    },
    "l1_contract": "$TAIKO_INBOX",
    "l2_contract": "$TAIKO_ANCHOR",
    "rpc": "$L2_RPC",
    "beacon_rpc": null,
    "verifier_address_forks": {
      "HEKLA": {
        "SGX": "$SGX_RETH_VERIFIER",
        "SP1": "$SP1_RETH_VERIFIER",
        "RISC0": "$RISC0_RETH_VERIFIER"
      },
      "ONTAKE": {
        "SGX": "$SGX_RETH_VERIFIER",
        "SP1": "$SP1_RETH_VERIFIER",
        "RISC0": "$RISC0_RETH_VERIFIER"
      },
      "PACAYA": {
        "SGX": "$SGX_RETH_VERIFIER",
        "SP1": "$SP1_RETH_VERIFIER",
        "RISC0": "$RISC0_RETH_VERIFIER"
      }
    },
    "genesis_time": 0,
    "seconds_per_slot": 1,
    "is_taiko": true
  }
]
EOF
  
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ âœ… Prover chain spec list json generated successfully,       â•‘"
  echo "â•‘ and saved to: configs/chain_spec_list_default.json           â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo
}

generate_prover_env_vars() {
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ Generating prover env vars...                                â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo

  # Set SGX_INSTANCE_ID from the JSON file
  if [ -f "deployment/sgx_instances.json" ]; then
    export SGX_INSTANCE_ID=$(cat deployment/sgx_instances.json | jq -r '.sgx_instance_id // "0"')
  else
    export SGX_INSTANCE_ID="0"
  fi

  echo ">>>>>>"
  echo "export SGX_INSTANCE_ID=$SGX_INSTANCE_ID"
  echo "export GROTH16_VERIFIER_ADDRESS=$RISC0_GROTH16_VERIFIER"
  echo "export SP1_VERIFIER_ADDRESS=$SUCCINCT_VERIFIER"
  echo ">>>>>>"
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ âœ… Prover env vars generated successfully,                   â•‘"
  echo "â•‘ please copy and paste them when you start the provers        â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo
}

deploy_l1() {
  mkdir -p deployment
  
  # Check if deployment is already completed
  if [ -f "deployment/deploy_l1.json" ]; then
    # Prompt user for starting a new deployment if the deployment results are already present
    echo
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘ âš ï¸  Surge L1 deployment already completed                     â•‘"
    echo "â•‘ (deploy_l1.json exists)                                      â•‘"
    echo "â•‘                                                              â•‘"
    echo "â•‘ Start a new deployment? (true/false) [default: false]        â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo
    read -r start_new_deployment
    START_NEW_DEPLOYMENT=${start_new_deployment:-false}

    if [ "$START_NEW_DEPLOYMENT" = "true" ]; then
      echo
      echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
      echo "â•‘ Starting a new deployment...                                 â•‘"
      echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      echo
      rm -f deployment/*.json
      ./surge-remover.sh
    else
      echo
      echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
      echo "â•‘ Using existing deployment...                                 â•‘"
      echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      echo
      return 0
    fi 
  fi

  # Check if deployment is currently running
  if [ -f "deployment/deploy_l1.lock" ]; then
    echo
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘ âš ï¸  Surge L1 deployment is already running (lock file exists) â•‘"
    echo "â•‘                                                              â•‘"
    echo "â•‘ Please wait for it to complete or remove the lock file if    â•‘"
    echo "â•‘ the previous deployment failed.                              â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo
    exit 1
  fi
  
  # Create lock file to indicate deployment is starting
  touch deployment/deploy_l1.lock
  
  # Ensure lock file is removed on script exit (success or failure)
  trap 'rm -f deployment/deploy_l1.lock' EXIT
  
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ Preparing Surge L1 SCs deployment...                         â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo

  # Prompt user for USE_TIMELOCKED_OWNER with default to false
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ Use timelocked owner? (true/false) [default: false]          â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo
  read -r timelocked_owner

  export USE_TIMELOCKED_OWNER=${timelocked_owner:-false}

  # Update USE_TIMELOCKED_OWNER in env file for other functions and scripts to use
  update_env_var ".env" "USE_TIMELOCKED_OWNER" "$USE_TIMELOCKED_OWNER"

  # Clean up backup file if it exists
  if [ -f ".env.bak" ]; then
    rm ".env.bak"
  fi

  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ Deploying Surge L1 SCs...                                    â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo

  BROADCAST=true USE_TIMELOCKED_OWNER=$USE_TIMELOCKED_OWNER docker compose -f docker-compose-protocol.yml --profile l1-deployer up
}

extract_l1_deployment_results() {
  # Extract L1 deployment results from deploy_l1.json
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ Extracting Surge L1 SCs deployment results...                â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo
  export TAIKO_INBOX=$(cat ./deployment/deploy_l1.json | jq -r '.taiko')
  export TAIKO_WRAPPER=$(cat ./deployment/deploy_l1.json | jq -r '.taiko_wrapper')
  export AUTOMATA_DCAP_ATTESTATION_GETH=$(cat ./deployment/deploy_l1.json | jq -r '.automata_dcap_attestation_geth')
  export AUTOMATA_DCAP_ATTESTATION_RETH=$(cat ./deployment/deploy_l1.json | jq -r '.automata_dcap_attestation_reth')
  export BRIDGE=$(cat ./deployment/deploy_l1.json | jq -r '.bridge')
  export ERC1155_VAULT=$(cat ./deployment/deploy_l1.json | jq -r '.erc1155_vault')
  export ERC20_VAULT=$(cat ./deployment/deploy_l1.json | jq -r '.erc20_vault')
  export ERC721_VAULT=$(cat ./deployment/deploy_l1.json | jq -r '.erc721_vault')
  export FORCED_INCLUSION_STORE=$(cat ./deployment/deploy_l1.json | jq -r '.forced_inclusion_store')
  
  # Handle potentially missing fields with jq's alternative operator
  export L1_OWNER=$(cat ./deployment/deploy_l1.json | jq -r '.l1_owner // "0x0000000000000000000000000000000000000000"')
  
  export PEM_CERT_CHAIN_LIB=$(cat ./deployment/deploy_l1.json | jq -r '.pem_cert_chain_lib')
  export PROOF_VERIFIER=$(cat ./deployment/deploy_l1.json | jq -r '.proof_verifier')
  export RISC0_GROTH16_VERIFIER=$(cat ./deployment/deploy_l1.json | jq -r '.risc0_groth16_verifier')
  export RISC0_RETH_VERIFIER=$(cat ./deployment/deploy_l1.json | jq -r '.risc0_reth_verifier')
  export SGX_GETH_VERIFIER=$(cat ./deployment/deploy_l1.json | jq -r '.sgx_geth_verifier')
  export SGX_RETH_VERIFIER=$(cat ./deployment/deploy_l1.json | jq -r '.sgx_reth_verifier')
  export SHARED_RESOLVER=$(cat ./deployment/deploy_l1.json | jq -r '.shared_resolver')
  export SIG_VERIFY_LIB=$(cat ./deployment/deploy_l1.json | jq -r '.sig_verify_lib')
  export SIGNAL_SERVICE=$(cat ./deployment/deploy_l1.json | jq -r '.signal_service')
  export SP1_RETH_VERIFIER=$(cat ./deployment/deploy_l1.json | jq -r '.sp1_reth_verifier')
  export SUCCINCT_VERIFIER=$(cat ./deployment/deploy_l1.json | jq -r '.succinct_verifier')
  
  # Handle potentially missing field with jq's alternative operator
  export SURGE_TIMELOCK_CONTROLLER=$(cat ./deployment/deploy_l1.json | jq -r '.surge_timelock_controller // "0x0000000000000000000000000000000000000000"')

  echo
  echo ">>>>>>"
  echo " TAIKO_INBOX: $TAIKO_INBOX "
  echo " TAIKO_WRAPPER: $TAIKO_WRAPPER "
  echo " AUTOMATA_DCAP_ATTESTATION_GETH: $AUTOMATA_DCAP_ATTESTATION_GETH "
  echo " AUTOMATA_DCAP_ATTESTATION_RETH: $AUTOMATA_DCAP_ATTESTATION_RETH "
  echo " BRIDGE: $BRIDGE "
  echo " ERC1155_VAULT: $ERC1155_VAULT "
  echo " ERC20_VAULT: $ERC20_VAULT "
  echo " ERC721_VAULT: $ERC721_VAULT "
  echo " FORCED_INCLUSION_STORE: $FORCED_INCLUSION_STORE "
  echo " L1_OWNER: $L1_OWNER "
  echo " PEM_CERT_CHAIN_LIB: $PEM_CERT_CHAIN_LIB "
  echo " PROOF_VERIFIER: $PROOF_VERIFIER "
  echo " RISC0_GROTH16_VERIFIER: $RISC0_GROTH16_VERIFIER "
  echo " RISC0_RETH_VERIFIER: $RISC0_RETH_VERIFIER "
  echo " SGX_GETH_VERIFIER: $SGX_GETH_VERIFIER "
  echo " SGX_RETH_VERIFIER: $SGX_RETH_VERIFIER "
  echo " SHARED_RESOLVER: $SHARED_RESOLVER "
  echo " SIG_VERIFY_LIB: $SIG_VERIFY_LIB "
  echo " SIGNAL_SERVICE: $SIGNAL_SERVICE "
  echo " SP1_RETH_VERIFIER: $SP1_RETH_VERIFIER "
  echo " SUCCINCT_VERIFIER: $SUCCINCT_VERIFIER "
  echo " SURGE_TIMELOCK_CONTROLLER: $SURGE_TIMELOCK_CONTROLLER "
  echo ">>>>>>"
  echo

  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ Updating .env with extracted values...                       â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo
  update_env_var ".env" "TAIKO_INBOX" "$TAIKO_INBOX"
  update_env_var ".env" "TAIKO_WRAPPER" "$TAIKO_WRAPPER"
  update_env_var ".env" "AUTOMATA_DCAP_ATTESTATION_GETH" "$AUTOMATA_DCAP_ATTESTATION_GETH"
  update_env_var ".env" "AUTOMATA_DCAP_ATTESTATION_RETH" "$AUTOMATA_DCAP_ATTESTATION_RETH"
  update_env_var ".env" "BRIDGE" "$BRIDGE"
  update_env_var ".env" "ERC1155_VAULT" "$ERC1155_VAULT"
  update_env_var ".env" "ERC20_VAULT" "$ERC20_VAULT"
  update_env_var ".env" "ERC721_VAULT" "$ERC721_VAULT"
  update_env_var ".env" "FORCED_INCLUSION_STORE" "$FORCED_INCLUSION_STORE"
  update_env_var ".env" "L1_OWNER" "$L1_OWNER"
  update_env_var ".env" "PEM_CERT_CHAIN_LIB" "$PEM_CERT_CHAIN_LIB"
  update_env_var ".env" "PROOF_VERIFIER" "$PROOF_VERIFIER"
  update_env_var ".env" "RISC0_GROTH16_VERIFIER" "$RISC0_GROTH16_VERIFIER"
  update_env_var ".env" "RISC0_RETH_VERIFIER" "$RISC0_RETH_VERIFIER"
  update_env_var ".env" "SGX_GETH_VERIFIER" "$SGX_GETH_VERIFIER"
  update_env_var ".env" "SGX_RETH_VERIFIER" "$SGX_RETH_VERIFIER"
  update_env_var ".env" "SHARED_RESOLVER" "$SHARED_RESOLVER"
  update_env_var ".env" "SIG_VERIFY_LIB" "$SIG_VERIFY_LIB"
  update_env_var ".env" "SIGNAL_SERVICE" "$SIGNAL_SERVICE"
  update_env_var ".env" "SP1_RETH_VERIFIER" "$SP1_RETH_VERIFIER"
  update_env_var ".env" "SUCCINCT_VERIFIER" "$SUCCINCT_VERIFIER"
  update_env_var ".env" "SURGE_TIMELOCK_CONTROLLER" "$SURGE_TIMELOCK_CONTROLLER"

  # Clean up backup file if it exists
  if [ -f ".env.bak" ]; then
    rm ".env.bak"
  fi
}

deploy_proposer_wrapper() {
  # Check if deployment is already completed
  if [ -f "deployment/proposer_wrappers.json" ]; then
    echo
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘ âš ï¸  Proposer Wrapper deployment already completed             â•‘"
    echo "â•‘ (proposer_wrappers.json exists)                              â•‘"
    echo "â•‘                                                              â•‘"
    echo "â•‘ Deployment will be skipped...                                â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo
    return 0
  else
    echo
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘ Deploying Surge Proposer Wrapper...                          â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo

    BROADCAST=true docker compose -f docker-compose-protocol.yml --profile proposer-wrapper-deployer up
  fi
}

extract_surge_proposer_wrapper() {
  export SURGE_PROPOSER_WRAPPER=$(cat ./deployment/proposer_wrappers.json | jq -r '.proposer_wrapper')

  echo
  echo ">>>>>>"
  echo " SURGE_PROPOSER_WRAPPER: $SURGE_PROPOSER_WRAPPER "
  echo ">>>>>>"
  echo

  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ Updating .env with proposer wrapper address...               â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo
  update_env_var ".env" "SURGE_PROPOSER_WRAPPER" "$SURGE_PROPOSER_WRAPPER"

  # Clean up backup file if it exists
  if [ -f ".env.bak" ]; then
    rm ".env.bak"
  fi
}

deploy_provers() {
  # Prompt user for RUNNING_PROVERS with default to false
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ Running provers? (true/false) [default: false]               â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo
  read -r running_provers

  RUNNING_PROVERS=${running_provers:-false}

  # If running provers is true, set up the verifiers
  if [ "$RUNNING_PROVERS" = "true" ]; then
    generate_prover_chain_spec

    if [ ! -f "deployment/sgx_verifier_setup.lock" ]; then
      # Prompt user for running SGX Raiko
      echo
      echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
      echo "â•‘ Running SGX Raiko? (true/false) [default: false]              â•‘"
      echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      echo
      read -r running_sgx_raiko
      RUNNING_SGX_RAIKO=${running_sgx_raiko:-false}

      if [ "$RUNNING_SGX_RAIKO" = "true" ]; then
        if [ "$MR_ENCLAVE" = "" ]; then
          echo
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘ â— SGX MR_ENCLAVE is not set,                                â•‘"
          echo "â•‘ please set it and rerun the script                           â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo
          exit 1
        fi

        if [ "$MR_SIGNER" = "" ]; then
          echo
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘ â— SGX MR_SIGNER is not set,                                 â•‘"
          echo "â•‘ please set it and rerun the script                           â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo
          exit 1
        fi

        if [ "$V3_QUOTE_BYTES" = "" ]; then
          echo
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘ â— SGX V3_QUOTE_BYTES is not set,                            â•‘"
          echo "â•‘ please set it and rerun the script                           â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo
          exit 1
        fi

        SGX_VERIFIER_ADDRESS=${SGX_RETH_VERIFIER} AUTOMATA_PROXY_ADDRESS=${AUTOMATA_DCAP_ATTESTATION_RETH} BROADCAST=true docker compose -f docker-compose-protocol.yml --profile sgx-verifier-setup up
      fi
    fi

    # if [ ! -f "deployment/sgx_geth_verifier_setup.lock" ]; then
    #   # Prompt user for running SGX Gaiko
    #   echo
    #   echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    #   echo "â•‘ Running SGX Gaiko? (true/false) [default: false]              â•‘"
    #   echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    #   echo
    #   read -r running_sgx_gaiko
    #   RUNNING_SGX_GAIKO=${running_sgx_gaiko:-false}

    #   if [ "$RUNNING_SGX_GAIKO" = "true" ]; then
    #     if [ "$GAIKO_MR_ENCLAVE" = "" ]; then
    #       echo
    #       echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    #       echo "â•‘ â— SGX GAIKO_MR_ENCLAVE is not set,                          â•‘"
    #       echo "â•‘ please set it and rerun the script                           â•‘"
    #       echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    #       echo
    #       exit 1
    #     fi

    #     if [ "$GAIKO_MR_SIGNER" = "" ]; then
    #       echo
    #       echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    #       echo "â•‘ â— SGX GAIKO_MR_SIGNER is not set,                           â•‘"
    #       echo "â•‘ please set it and rerun the script                           â•‘"
    #       echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    #       echo
    #       exit 1
    #     fi

    #     if [ "$GAIKO_V3_QUOTE_BYTES" = "" ]; then
    #       echo
    #       echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    #       echo "â•‘ â— SGX GAIKO_V3_QUOTE_BYTES is not set,                      â•‘"
    #       echo "â•‘ please set it and rerun the script                           â•‘"
    #       echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    #       echo
    #       exit 1
    #     fi

    #     docker compose -f docker-compose-protocol.yml --profile sgx-geth-verifier-setup up
    #   fi
    # fi

    if [ ! -f "deployment/sp1_verifier_setup.lock" ]; then
      # Prompt user for running SP1 Raiko
      echo
      echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
      echo "â•‘ Running SP1? (true/false) [default: false]                   â•‘"
      echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      echo
      read -r running_sp1_raiko
      RUNNING_SP1_RAIKO=${running_sp1_raiko:-false}

      if [ "$RUNNING_SP1_RAIKO" = "true" ]; then
        if [ "$SP1_BLOCK_PROVING_PROGRAM_VKEY" = "" ]; then
          echo
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘ â— SP1_BLOCK_PROVING_PROGRAM_VKEY is not set,                â•‘"
          echo "â•‘ please set it and rerun the script                           â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo
          exit 1
        fi

        if [ "$SP1_AGGREGATION_PROGRAM_VKEY" = "" ]; then
          echo
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘ â— SP1_AGGREGATION_PROGRAM_VKEY is not set                   â•‘"
          echo "â•‘ please set it and rerun the script                           â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo
          exit 1
        fi

        BROADCAST=true docker compose -f docker-compose-protocol.yml --profile sp1-verifier-setup up
      fi
    fi

    if [ ! -f "deployment/risc0_verifier_setup.lock" ]; then
      # Prompt user for running RISC0 Raiko
      echo
      echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
      echo "â•‘ Running RISC0? (true/false) [default: false]                 â•‘"
      echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      echo
      read -r running_risc0_raiko
      RUNNING_RISC0_RAIKO=${running_risc0_raiko:-false}

      if [ "$RUNNING_RISC0_RAIKO" = "true" ]; then
        if [ "$RISC0_BLOCK_PROVING_IMAGE_ID" = "" ]; then
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘ â— RISC0_BLOCK_PROVING_IMAGE_ID is not set,                  â•‘"
          echo "â•‘ please set it and rerun the script                           â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo
          exit 1
        fi

        if [ "$RISC0_AGGREGATION_IMAGE_ID" = "" ]; then
          echo
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘ â— RISC0_AGGREGATION_IMAGE_ID is not set,                    â•‘"
          echo "â•‘ please set it and rerun the script                           â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo
          exit 1
        fi

        BROADCAST=true docker compose -f docker-compose-protocol.yml --profile risc0-verifier-setup up
      fi
    fi

    # Generate prover env vars once set up the verifiers
    generate_prover_env_vars
  fi
}

deposit_bond() {
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ Depositing bond...                                           â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo

  # Prompt user for deposit bond
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ Deposit bond? (true/false) [default: true]                   â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo
  read -r deposit_bond

  DEPOSIT_BOND=${deposit_bond:-true}

  if [ "$DEPOSIT_BOND" = "true" ]; then 
    # Prompt user for BOND_AMOUNT
    echo
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘ Enter bond amount (in ETH, default: 1000)                    â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo
    read -r bond_amount

    BOND_AMOUNT=${bond_amount:-1000}

    # Convert to wei
    export BOND_AMOUNT=$(echo "$BOND_AMOUNT * 1000000000000000000" | bc | cut -d. -f1)

    docker compose -f docker-compose-protocol.yml --profile bond-deposit up
  else
    return 0
  fi
}

deploy_surge_protocol() {
  # Deploy L1 SCs
  deploy_l1

  # Extract L1 deployment results
  extract_l1_deployment_results

  # Deploy Surge Proposer Wrapper
  deploy_proposer_wrapper

  # Extract Surge Proposer Wrapper address
  extract_surge_proposer_wrapper

  # Deploy Provers
  deploy_provers

  # Deposit bond
  deposit_bond

  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘ âœ… Surge Protocol deployment completed successfully          â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘                     ğŸ”§ NEXT ACTION: ğŸ”§                       â•‘"
  echo "â•‘                                                              â•‘"
  echo "â•‘     Run ./surge-stack-deployer.sh to start the L2 stack      â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo
}

deploy_surge_protocol
